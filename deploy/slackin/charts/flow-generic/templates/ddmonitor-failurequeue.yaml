{{- $fullName := include "deploy.fullname" . -}}
{{- $ddmonitors := .Values.datadogMonitors -}}

{{- $warningnotiftarget := printf "@slack-team-%s-notifications" $.Values.team -}}
{{- $alertnotiftarget := printf "@pagerduty-%s" $.Values.team  -}}

{{- range $monitortype := $ddmonitors }}
{{- if eq $monitortype.type "flow.lib_postgres_play.db.failure_queue.length-avg" }}

apiVersion: datadoghq.com/v1alpha1
kind: DatadogMonitor
metadata:
  {{- if $monitortype.name }}
  name: {{ $fullName }}-failurequeue-{{ $monitortype.name }}
  {{- else }}
  name: {{ $fullName }}-failurequeue
  {{- end }}
  namespace: datadog
spec:
  options:
    notifyAudit: true
    renotifyInterval: 1440
    thresholds:
      {{- if $monitortype.warning }}
      warning: "{{ default "8" $monitortype.warning.threshold }}"
      {{- else }}
      warning: "1"
      {{- end }}
      {{- if $monitortype.alert }}
      critical: "{{ default "10" $monitortype.alert.threshold }}"
      {{- else }}
      critical: "10"
      {{- end }}
    newGroupDelay: {{ default 600 $monitortype.newGroupDelay }}
  query: >
    {{ default "avg" $monitortype.monitorMainOperator }}(
      {{ default "last_5m" $monitortype.interval }}
    ):avg:flow.lib_postgres_play.db.failure_queue.length{
      env:live AND
      service:{{ $fullName }}
      {{- if $monitortype.filters }}
        AND ({{ $monitortype.filters }})
      {{- end }}
    } by {
      fulltablename,
      service
    } >=
      {{- if $monitortype.alert }}
        {{ default "10" $monitortype.alert.threshold }}
      {{- else }}
        10
      {{- end }}
  type: "query alert"
  name: "[generated] Service {{ $fullName }} {{ default "" $monitortype.name }} failure queue length table {{ "{{" }}fulltablename.name{{ "}}" }} is high"
  message: |
    {{ $fullName }} {{ default "" $monitortype.name }} failure queue length table {{ "{{" }}fulltablename.name{{ "}}" }} is high.

    Comment: {{ default "\n" $monitortype.comment }}

    {{- if $monitortype.warning }}
    {{ default $warningnotiftarget $monitortype.warning.notificationTarget }}
    {{- else }}
    {{ $warningnotiftarget }}
    {{- end }}

    {{ "{{" }}#is_alert{{ "}}" }}
      {{- if $monitortype.alert }}
      {{ default $alertnotiftarget $monitortype.alert.notificationTarget }}
      {{- else }}
      {{ $alertnotiftarget }}
      {{- end }}
    {{ "{{" }}/is_alert{{ "}}" }}
          
    {{ "{{" }}#is_alert_recovery{{ "}}" }}
      {{- if $monitortype.alert }}
      {{ default $alertnotiftarget $monitortype.alert.notificationTarget }}
      {{- else }}
      {{ $alertnotiftarget }}
      {{- end }}
    {{ "{{" }}/is_alert_recovery{{ "}}" }}
    
    To resolve try requeueing the failed journal records in the database by running the following command on dbgateway: 
    
    ```
    db <dbname> requeue_failures
    ```

  tags:
    - "service:{{ $fullName }}"
    - "env:live"
    - "team:{{ $.Values.team }}"

---

{{- end }}
{{- end }}
